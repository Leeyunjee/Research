{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "jdJuRgMQ4RwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfKqN-3Evn8V"
      },
      "source": [
        "**shift(0,30,60,90,120,150,180,210,240,270,300,330,360)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StuJjxxKDGwj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"UK_research2.csv\", encoding=\"utf-8\").drop(columns=\"Unnamed: 0\")\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
        "#df[['Headline', 'gold', 'oil', 'bond', 'cad', 'cny', 'eur', 'jpy', 'usd']] = df[['Headline', 'gold', 'oil', 'bond', 'cad', 'cny', 'eur', 'jpy', 'usd']].shift(30)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv8Y3nrvDGzG"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[['gold', 'oil', 'bond', 'cad', 'cny', 'eur', 'jpy', 'usd']] = scaler.fit_transform(df[['gold', 'oil', 'bond', 'cad', 'cny', 'eur', 'jpy', 'usd']])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "gDSRctpAk1Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "mDZjty2fkZAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To9f1_ADDG3j"
      },
      "outputs": [],
      "source": [
        "stopwords_object = stopwords.words('english')\n",
        "df[\"Headline\"] = df[\"Headline\"].str.lower()\n",
        "\n",
        "def preprocessing_text(data):\n",
        "    if type(data) is float:\n",
        "      data = str(data);\n",
        "\n",
        "    data = re.sub(\"[^a-zA-Z]\",\" \", data)\n",
        "\n",
        "    tokens = word_tokenize(data)\n",
        "    word_tokens = [w for w in tokens if w not in stopwords_object]\n",
        "\n",
        "\n",
        "    stemmer = PorterStemmer()\n",
        "    stem_words = [stemmer.stem(w) for w in word_tokens]\n",
        "\n",
        "\n",
        "    lemmer = WordNetLemmatizer()\n",
        "    lem_words = [lemmer.lemmatize(w) for w in stem_words]\n",
        "\n",
        "    return \" \".join(lem_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNRWJ-RfQ2rS"
      },
      "outputs": [],
      "source": [
        "df[\"Headline2\"] = df[\"Headline\"].apply(preprocessing_text)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA1FPTtURS_Q"
      },
      "source": [
        "## **TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf6g2rm-Q2tc"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of0u6lKsQ2vZ"
      },
      "outputs": [],
      "source": [
        "tfidf_result = tfidf.fit_transform(df[\"Headline2\"])\n",
        "df[\"tfidf_Headline\"] = list(tfidf_result.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHieI7YtQ2xh"
      },
      "outputs": [],
      "source": [
        "df[\"tfidf_Headline\"] = np.array(df['tfidf_Headline'].tolist())\n",
        "X = df[['tfidf_Headline', 'gold', 'oil', 'bond', 'cad', 'cny', 'eur', 'jpy', 'usd']]\n",
        "y = df[\"ETF\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJNGPyXrRY-3"
      },
      "source": [
        "### **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgMXPkSfQ2zY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=20, min_samples_split=2, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "rf_predictions = rf.predict(X_test)\n",
        "\n",
        "rf_rmse = mean_squared_error(y_test, rf_predictions, squared=False)\n",
        "print(f\"Random Forest RMSE: {rf_rmse}\")\n",
        "\n",
        "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
        "print(f\"Random Forest MAE: {rf_mae}\")\n",
        "\n",
        "rf_mape = mean_absolute_percentage_error(y_test, rf_predictions)\n",
        "print(f\"Random Forest MAPE: {rf_mape}\")\n",
        "\n",
        "r2 = r2_score(y_test, rf_predictions)\n",
        "print(f'Random Forest R제곱: {r2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeO_jNC2Q21U"
      },
      "outputs": [],
      "source": [
        "feature_importances = rf.feature_importances_\n",
        "\n",
        "for feature, importance in zip(X_train.columns, feature_importances):\n",
        "    print(f\"{feature}: {importance}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 3))\n",
        "plt.plot(y_test, label='Actual', color='green')\n",
        "plt.plot(rf_predictions, label='Predicted', color='orange', linestyle='-')\n",
        "plt.title('M+1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nwpyIAT8kpVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L6GVn1NRmYU"
      },
      "source": [
        "### **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdETtrUsQ23W"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from keras.layers import PReLU\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "X_lstm_train = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
        "y_lstm_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
        "\n",
        "X_lstm_val = np.reshape(X_val.values, (X_val.shape[0], X_val.shape[1], 1))\n",
        "y_lstm_val = np.reshape(y_val, (y_val.shape[0], 1))\n",
        "\n",
        "X_lstm_test = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
        "y_lstm_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(784, input_shape=(X_lstm_train.shape[1], X_lstm_train.shape[2])))\n",
        "#lstm_model.add(Dense(100, activation='relu'))\n",
        "lstm_model.add(Dense(256))\n",
        "lstm_model.add(PReLU())\n",
        "#lstm_model.add(Dense(50, activation='relu'))\n",
        "lstm_model.add(Dense(64))\n",
        "lstm_model.add(PReLU())\n",
        "lstm_model.add(Dense(1, activation='linear'))\n",
        "lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mape'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RonV66WgQ25W"
      },
      "outputs": [],
      "source": [
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVpFKyquQ27R"
      },
      "outputs": [],
      "source": [
        "history = lstm_model.fit(X_lstm_train, y_lstm_train, epochs=300, batch_size=32,\n",
        "                         validation_data=(X_lstm_val, y_lstm_val),verbose=1)\n",
        "\n",
        "lstm_predictions = lstm_model.predict(X_lstm_test)\n",
        "\n",
        "lstm_rmse = mean_squared_error(y_lstm_test, lstm_predictions, squared=False)\n",
        "print(f\"LSTM RMSE: {lstm_rmse}\")\n",
        "\n",
        "lstm_mae = mean_absolute_error(y_lstm_test, lstm_predictions)\n",
        "print(f\"LSTM MAE: {lstm_mae}\")\n",
        "\n",
        "lstm_mape = mean_absolute_percentage_error(y_lstm_test, lstm_predictions)\n",
        "print(f\"LSTM MAPE: {lstm_mape}\")\n",
        "\n",
        "r2 = r2_score(y_lstm_test, lstm_predictions)\n",
        "print(f'LSTM R제곱: {r2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hybrid**"
      ],
      "metadata": {
        "id": "aW76iEMoUiFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['gold', 'oil', 'cny', 'jpy', 'usd']]\n",
        "y = df[\"ETF\"].values\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "X_lstm_train = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
        "y_lstm_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
        "\n",
        "X_lstm_val = np.reshape(X_val.values, (X_val.shape[0], X_val.shape[1], 1))\n",
        "y_lstm_val = np.reshape(y_val, (y_val.shape[0], 1))\n",
        "\n",
        "X_lstm_test = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
        "y_lstm_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(784, input_shape=(X_lstm_train.shape[1], X_lstm_train.shape[2])))\n",
        "#lstm_model.add(Dense(100, activation='relu'))\n",
        "lstm_model.add(Dense(256))\n",
        "lstm_model.add(PReLU())\n",
        "#lstm_model.add(Dense(50, activation='relu'))\n",
        "lstm_model.add(Dense(64))\n",
        "lstm_model.add(PReLU())\n",
        "lstm_model.add(Dense(1, activation='linear'))\n",
        "lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mape'])\n",
        "\n",
        "history = lstm_model.fit(X_lstm_train, y_lstm_train, epochs=300, batch_size=32,\n",
        "                         validation_data=(X_lstm_val, y_lstm_val),verbose=1)\n",
        "\n",
        "lstm_predictions = lstm_model.predict(X_lstm_test)\n",
        "\n",
        "lstm_rmse = mean_squared_error(y_lstm_test, lstm_predictions, squared=False)\n",
        "print(f\"LSTM RMSE: {lstm_rmse}\")\n",
        "\n",
        "lstm_mae = mean_absolute_error(y_lstm_test, lstm_predictions)\n",
        "print(f\"LSTM MAE: {lstm_mae}\")\n",
        "\n",
        "lstm_mape = mean_absolute_percentage_error(y_lstm_test, lstm_predictions)\n",
        "print(f\"LSTM MAPE: {lstm_mape}\")\n",
        "\n",
        "r2 = r2_score(y_lstm_test, lstm_predictions)\n",
        "print(f'LSTM R제곱: {r2}')"
      ],
      "metadata": {
        "id": "0BH1WBFcUidM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uG3kVZIU1zm"
      },
      "source": [
        "## **BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFkfwtLsDG6b"
      },
      "outputs": [],
      "source": [
        "!pip install pandas transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYtkpVMzU0tg"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "df['headline']=df[\"Headline\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpwcvLyUU0vQ"
      },
      "outputs": [],
      "source": [
        "tokenized_headlines = df['headline'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "max_len = max(map(len, tokenized_headlines))\n",
        "padded_headlines = torch.tensor([i + [0]*(max_len-len(i)) for i in tokenized_headlines])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF3TH-31U0xN"
      },
      "outputs": [],
      "source": [
        "attention_mask = (padded_headlines != 0).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyosJXabU0zA"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(padded_headlines, attention_mask=attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfdFYiqCU01A"
      },
      "outputs": [],
      "source": [
        "bert_embeddings = outputs.last_hidden_state[:, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGEeEB_LU03F"
      },
      "outputs": [],
      "source": [
        "bert_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBN6jeTOU05L"
      },
      "outputs": [],
      "source": [
        "bert_headline = bert_embeddings.tolist()\n",
        "df['bert_headline'] = bert_headline\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jBxruSHVIdi"
      },
      "source": [
        "## **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8-7uF2qU07X"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "\n",
        "df[\"bert_headline\"] = np.array(df['bert_headline'].tolist())\n",
        "X = df[['bert_headline', 'gold', 'oil', 'bond', 'cad', 'cny', 'eur', 'jpy', 'usd']]\n",
        "y = df[\"ETF\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
        "\n",
        "rf2 = RandomForestRegressor(n_estimators=100, max_depth=20, min_samples_split=2, random_state=20)\n",
        "rf2.fit(X_train, y_train)\n",
        "\n",
        "rf2_predictions = rf2.predict(X_test)\n",
        "\n",
        "rf_rmse = mean_squared_error(y_test, rf2_predictions, squared=False)\n",
        "print(f\"Random Forest RMSE: {rf_rmse}\")\n",
        "\n",
        "rf_mae = mean_absolute_error(y_test, rf2_predictions)\n",
        "print(f\"Random Forest MAE: {rf_mae}\")\n",
        "\n",
        "rf_mape = mean_absolute_percentage_error(y_test, rf2_predictions)\n",
        "print(f\"Random Forest MAPE: {rf_mape}\")\n",
        "\n",
        "r2 = r2_score(y_test, rf2_predictions)\n",
        "print(f'Random Forest R제곱: {r2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqwZ2QPMU09Y"
      },
      "outputs": [],
      "source": [
        "feature_importances = rf2.feature_importances_\n",
        "\n",
        "for feature, importance in zip(X_train.columns, feature_importances):\n",
        "    print(f\"{feature}: {importance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7Q_77u_VTRS"
      },
      "source": [
        "## **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIzcVxt9U0_g"
      },
      "outputs": [],
      "source": [
        "from keras.layers import PReLU\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "df[\"bert_headline\"] = np.array(df['bert_headline'].tolist())\n",
        "X = df[['bert_headline', 'gold', 'oil', 'bond', 'cad', 'cny', 'eur', 'jpy', 'usd']]\n",
        "y = df[\"ETF\"].values\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "X_lstm_train = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
        "y_lstm_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
        "\n",
        "X_lstm_val = np.reshape(X_val.values, (X_val.shape[0], X_val.shape[1], 1))\n",
        "y_lstm_val = np.reshape(y_val, (y_val.shape[0], 1))\n",
        "\n",
        "X_lstm_test = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
        "y_lstm_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
        "\n",
        "lstm2_model = Sequential()\n",
        "lstm2_model.add(LSTM(784, input_shape=(X_lstm_train.shape[1], X_lstm_train.shape[2])))\n",
        "lstm2_model.add(Dense(256))\n",
        "lstm2_model.add(PReLU())\n",
        "lstm2_model.add(Dense(64))\n",
        "lstm2_model.add(PReLU())\n",
        "lstm2_model.add(Dense(1, activation='linear'))\n",
        "lstm2_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mape'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcNZD2rzU1By"
      },
      "outputs": [],
      "source": [
        "lstm2_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "374i7l4tU1EA"
      },
      "outputs": [],
      "source": [
        "history = lstm2_model.fit(X_lstm_train, y_lstm_train, epochs=300, batch_size=32,\n",
        "                         validation_data=(X_lstm_val, y_lstm_val),verbose=1)\n",
        "\n",
        "lstm_predictions = lstm2_model.predict(X_lstm_test)\n",
        "\n",
        "lstm_rmse = mean_squared_error(y_lstm_test, lstm_predictions, squared=False)\n",
        "print(f\"LSTM RMSE: {lstm_rmse}\")\n",
        "\n",
        "lstm_mae = mean_absolute_error(y_lstm_test, lstm_predictions)\n",
        "print(f\"LSTM MAE: {lstm_mae}\")\n",
        "\n",
        "lstm_mape = mean_absolute_percentage_error(y_lstm_test, lstm_predictions)\n",
        "print(f\"LSTM MAPE: {lstm_mape}\")\n",
        "\n",
        "r2 = r2_score(y_lstm_test, lstm_predictions)\n",
        "print(f'LSTM R제곱: {r2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hybrid**"
      ],
      "metadata": {
        "id": "VY0Ei6hwUzBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['gold', 'oil', 'cny', 'jpy', 'usd']]\n",
        "y = df[\"ETF\"].values\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "X_lstm_train = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
        "y_lstm_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
        "\n",
        "X_lstm_val = np.reshape(X_val.values, (X_val.shape[0], X_val.shape[1], 1))\n",
        "y_lstm_val = np.reshape(y_val, (y_val.shape[0], 1))\n",
        "\n",
        "X_lstm_test = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
        "y_lstm_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
        "\n",
        "lstm2_model = Sequential()\n",
        "lstm2_model.add(LSTM(784, input_shape=(X_lstm_train.shape[1], X_lstm_train.shape[2])))\n",
        "lstm2_model.add(Dense(256))\n",
        "lstm2_model.add(PReLU())\n",
        "lstm2_model.add(Dense(64))\n",
        "lstm2_model.add(PReLU())\n",
        "lstm2_model.add(Dense(1, activation='linear'))\n",
        "lstm2_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mape'])\n",
        "\n",
        "history = lstm2_model.fit(X_lstm_train, y_lstm_train, epochs=300, batch_size=32,\n",
        "                         validation_data=(X_lstm_val, y_lstm_val),verbose=1)\n",
        "\n",
        "lstm_predictions = lstm2_model.predict(X_lstm_test)\n",
        "\n",
        "lstm_rmse = mean_squared_error(y_lstm_test, lstm_predictions, squared=False)\n",
        "print(f\"LSTM RMSE: {lstm_rmse}\")\n",
        "\n",
        "lstm_mae = mean_absolute_error(y_lstm_test, lstm_predictions)\n",
        "print(f\"LSTM MAE: {lstm_mae}\")\n",
        "\n",
        "lstm_mape = mean_absolute_percentage_error(y_lstm_test, lstm_predictions)\n",
        "print(f\"LSTM MAPE: {lstm_mape}\")\n",
        "\n",
        "r2 = r2_score(y_lstm_test, lstm_predictions)\n",
        "print(f'LSTM R제곱: {r2}')"
      ],
      "metadata": {
        "id": "PcCluMiQUyoT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}